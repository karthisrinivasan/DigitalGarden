[[Research]] [[Neuroscience]] [[Machine Learning]]

# Random synaptic feedback weights support error backpropagation
[[Timothy Lillicrap]] [[Colin Akerman]]

- Backprop computes feedback by multiplying error signals e by the weight matrix WT, which is the transpose of the forward synaptic connections W

Algorithm is based on three insights: 
- (i) the feedback weights need not be exactly $W^T$. In fact, any matrix B will suffice, so long as on average, $e^TWBe>0$, where $e$ is the error in the network’s output). Geometrically, this means the teaching signal sent by the matrix, $Be$, lies within 90 of the signal used by backprop, $W^Te$, that is, $B$ pushes the network in roughly the same direction as backprop would. To learn with any speed though, we need better agreement between $B$ and $W^T$. 
- (ii) To that end, the network could evolve to bring $B$ and $W^T$ into alignment. The obvious option is to adjust $B$, but 
- (iii) another possibility is to do the same by adjusting $W$. We will show this can be achieved very simply, even with a fixed, random $B$.

Network:
- ![[Pasted image 20210713152439.png]]
	- a -> 3 weights on bottom must match 3 in network
	- b -> backprop requires ideal weight matrix
	- c -> new algorithm only needs random matrix $B$, with some constraints on it
	- d -> possible neural circuitry; others are possible
-
## Algorithm:
- To change weights in $W_0$: $\Delta W_0$~$Bex^T$
- Modulator vector -> $\delta=Be$
- Constraint -> The modulator vector generated by $B$ should be close in angle to the one generated by $W$
- ![[Pasted image 20210713153026.png]]
	- a -> Normalized Square error with different algorithms
	- b -> Angle between the two modulator vectors
- Angle shrinks since $B$ starts acting like $W^T$ during training
	- Performs just as well even with non-zero angle
- Works on much larger networks; binary stochastic unit networks too

## Why do $B$ and $W^T$ align?
- Information about $B$ accumulates in $W_0$, which is passed to $W$ 
- ![[Pasted image 20210713154040.png]]
	- b -> information flow: Synaptic weight information from $B$ flows back into $W_0$ (1) and then forward into $W$ (2). As $W$ aligns with $B^T$, $B$ begins to act like $W^T$, sending useful teaching signals to the hidden units (3)
- Demonstrated by phased learning
	- ![[Pasted image 20210713154120.png]]
	- After information in $B$ has traveled via $W_0$ into $W$ in the first two phases, learning in the hidden layer now becomes effective, driven by errors propagated through $B$
- Additional experiments and analytic results suggested that feedback alignment may actually encourage $W$ to align with the Moore–Penrose pseudoinverse of $B$ - a matrix that can be shown to be at least as useful as the transpose for conveying error.
- What is crucial for effective error transmission is approximate functional symmetry. That is, $B$ only needs to act like $W^T$, and feedback alignment demonstrates that this requirement is almost trivial to meet.